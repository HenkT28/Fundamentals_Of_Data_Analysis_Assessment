# Fundamentals of Data Analysis Assessment 2019

This repository contains all my work in regards to my Assessment 2019 for the module Fundamentals of Data Analysis.

To access the repository, please go through below instructions:

1). Go to Github web site - User Account: HenkT28

<https://github.com/HenkT28>

2). Then go to Repositories, and select Fundamentals_Of_Data_Analysis_Assessment. Alternatively go to "Clone or download" drop down menu and copy below url:

<https://github.com/HenkT28/Fundamentals_Of_Data_Analysis_Assessment.git>

Then open up cmder (see futher below for download instructions) and run below command to clone the repository locally on your machine:

* git clone <https://github.com/HenkT28/Fundamentals_Of_Data_Analysis_Assessment.git>

STUDENT: Henk Tjalsma

GMIT email address: G00376321@gmit.ie

## Problem statement

This assessment concerns the well-known Tips [6] dataset and the Python [1] packages seaborn [5] and jupyter [4]. The project is broken into three parts, as follows:

1). Description:

* I created a git repository and made it available online for the lecturer to clone. The repository contains all the work for this assessment.
* Within the repository, create a jupyter [4] notebook that uses descriptive statistics and plots to describe the Tips [6] dataset.

2). Regression:

* To the jupyter notebook add a section that discusses and analyses whether there is a relationship between the total bill and tip amount.

3). Analyse:

* Again using the same notebook, analyse the relationship between the variables within the dataset. You are free to interpret this as you wish — for example, you may analyse all pairs of variables, or select a subset and analyse those.

## Installing Cmder, Visual Studio Code and Ananconda (which includes Jupyter, Pandas, Matplotlib, Seaborn and NumPy)

* Anaconda Distribution

The open-source Anaconda Distribution is the easiest way to perform Python/R data science and machine learning on Linux, Windows, and Mac OS X. With over 15 million users worldwide. [8]

It is the industry standard for developing, testing, and training on a single machine, enabling individual data scientists to:

    Quickly download 1,500+ Python/R data science packages.
    Manage libraries, dependencies, and environments with Conda.
    Develop and train machine learning and deep learning models with scikit-learn, TensorFlow, and Theano.
    Analyze data with scalability and performance with Dask, NumPy, pandas, and Numba.
    Visualize results with Matplotlib, Bokeh, Seaborn, Datashader, and Holoviews.

Anaconda is free and easy to install, and it offers free community support.

Anaconda3 includes Python 3.7.

<https://www.anaconda.com/distribution/>

<https://docs.anaconda.com/anaconda/>

* Jupyter Notebook

The Jupyter Notebook [4] is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.

As I have Anaconda installed, there was no need to install Jupyter separately.

<https://jupyter.org/install>

* Seaborn

Seaborn is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics. Again it comes installed with Anaconda. [7]

* NumPy

NumPy is the fundamental package for scientific computing with Python. It contains among other things [32]:

    A powerful N-dimensional array object.

    Sophisticated (broadcasting) functions.

    Tools for integrating C/C++ and Fortran code.

    Useful linear algebra, Fourier transform, and random number capabilities.

* Pandas

Pandas is a common Python tool for data manipulation and analysis, and is included with Anaconda. [33]

* Matplotlib

Matplotlib is a python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. Matplotlib can be used in Python scripts, the Python and IPython shell (ala MATLAB or Mathematica), web application servers, and six graphical user interface toolkits. It comes with anaconda package distribution. [34]

* Cmder

Cmder is a software package which provides a nice command line interface on Windows. [10]

I use Cmder for changing the working directory on my local machine, i.e. Fundamentals_Of_Data_Analysis_Assessment, from there I launch "jupyter notebook" command, and make changes to it.

<https://cmder.net/>

* Visual Studio Code

VS Code is a lightweight but powerful source code editor.

VS Code is a new type of tool that combines the simplicity of a code editor with what developers need for their core edit-build-debug cycle. Code provides comprehensive editing and debugging support, an extensibility model, and lightweight integration with existing tools. [31]

I use it to make changes to the readme in my repository.

<https://code.visualstudio.com/>

## HowTo run Jupyter notebook

I'll be using Jupyter Notebook not Jupyter Lab in this assignment (see below the difference between the 2 interfaces):

-> Jupyter Notebook is a web-based interactive computational environment for creating Jupyter notebooks documents. It supports several languages like Python (IPython), Julia, R etc, and is largely used for data analysis, data visualization and further interactive, exploratory computing.

-> Jupyter Lab is a popular 'new' interface for working with Jupyter Notebooks. It is an interactive development environment for working with notebooks, code and data — and hence extremely extensible.

Once I'm in the correct working directory, I start jupyter by running "jupyter notebook" command through Cmder.

The jupyter notebook is called Tips_Dataset.ipynb, and contains the body of my work.
